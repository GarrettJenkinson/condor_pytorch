{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONDOR CNN for predicting handwritten digits (MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial explains how to equip a deep neural network with the CONDOR layer and loss function for ordinal regression. Please note that **MNIST is not an ordinal dataset**. The reason why we use MNIST in this tutorial is that it is included in the PyTorch's `torchvision` library and is thus easy to work with, since it doesn't require extra data downloading and preprocessing steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 -- Setting up the dataset and dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we set up the data set and data loaders. This is a general procedure that is not specific to CONDOR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0.1%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on cpu\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "102.8%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "19.9%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "112.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Processing...\n",
      "Done!\n",
      "Image batch dimensions: torch.Size([128, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/m191034/opt/anaconda3/envs/condor_pytorch/lib/python3.9/site-packages/torchvision/datasets/mnist.py:502: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /tmp/pip-req-build-5cal76n6/torch/csrc/utils/tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "##########################\n",
    "### SETTINGS\n",
    "##########################\n",
    "\n",
    "# Hyperparameters\n",
    "random_seed = 1\n",
    "learning_rate = 0.05\n",
    "num_epochs = 10\n",
    "batch_size = 128\n",
    "\n",
    "# Architecture\n",
    "NUM_CLASSES = 10\n",
    "\n",
    "# Other\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Training on', DEVICE)\n",
    "\n",
    "##########################\n",
    "### MNIST DATASET\n",
    "##########################\n",
    "\n",
    "\n",
    "# Note transforms.ToTensor() scales input images\n",
    "# to 0-1 range\n",
    "train_dataset = datasets.MNIST(root='data', \n",
    "                               train=True, \n",
    "                               transform=transforms.ToTensor(),\n",
    "                               download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='data', \n",
    "                              train=False, \n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          drop_last=True,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset, \n",
    "                         batch_size=batch_size, \n",
    "                         drop_last=True,\n",
    "                         shuffle=False)\n",
    "\n",
    "# Checking the dataset\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Equipping CNN with CONDOR layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we are using  `condor_pytorch` to outfit a convolutional neural network for ordinal regression. Note that the CONDOR method only requires replacing the last (output) layer, which is typically a fully-connected layer, by the CONDOR layer.\n",
    "\n",
    "Using the `Sequential` API, we specify the CORAl layer as \n",
    "\n",
    "```python\n",
    "        self.fc = torch.nn.Linear(size_in=294, num_classes=num_classes-1)\n",
    "```\n",
    "\n",
    "This is because the convolutional and pooling layers \n",
    "\n",
    "```python\n",
    "            torch.nn.Conv2d(1, 3, (3, 3), (1, 1), 1),\n",
    "            torch.nn.MaxPool2d((2, 2), (2, 2)),\n",
    "            torch.nn.Conv2d(3, 6, (3, 3), (1, 1), 1),\n",
    "            torch.nn.MaxPool2d((2, 2), (2, 2)))\n",
    "```\n",
    "\n",
    "\n",
    "produce a flattened feature vector of 294 units. Then, when using the CONDOR layer in the forward function\n",
    "\n",
    "```python\n",
    "        logits =  self.fc(x)\n",
    "```\n",
    "\n",
    "please use the `sigmoid` not softmax function (since the CONDOR method uses a concept known as extended binary classification as described in the paper)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes):\n",
    "        super(ConvNet, self).__init__()\n",
    "        \n",
    "        self.features = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 3, (3, 3), (1, 1), 1),\n",
    "            torch.nn.MaxPool2d((2, 2), (2, 2)),\n",
    "            torch.nn.Conv2d(3, 6, (3, 3), (1, 1), 1),\n",
    "            torch.nn.MaxPool2d((2, 2), (2, 2)))\n",
    "        \n",
    "        self.fc = torch.nn.Linear(294,num_classes-1) #THIS IS KEY OUTPUT SIZE \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        logits =  self.fc(x)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    \n",
    "    \n",
    "torch.manual_seed(random_seed)\n",
    "model = ConvNet(num_classes=NUM_CLASSES)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Using the CONDOR loss for model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, all you need to do is to \n",
    "\n",
    "1) convert the integer class labels into the extended binary label format using the `levels_from_labelbatch` provided via `condor_pytorch`:\n",
    "\n",
    "```python\n",
    "        levels = levels_from_labelbatch(class_labels, \n",
    "                                        num_classes=NUM_CLASSES)\n",
    "```\n",
    "\n",
    "2) Apply the CONDOR loss (also provided via `condor_pytorch`):\n",
    "\n",
    "```python\n",
    "        cost = condor_negloglikeloss(logits, levels)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/m191034/opt/anaconda3/envs/condor_pytorch/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /tmp/pip-req-build-5cal76n6/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/010 | Batch 000/468 | Cost: 3.9491\n",
      "Epoch: 001/010 | Batch 200/468 | Cost: 0.7655\n",
      "Epoch: 001/010 | Batch 400/468 | Cost: 0.4426\n",
      "Epoch: 002/010 | Batch 000/468 | Cost: 0.5158\n",
      "Epoch: 002/010 | Batch 200/468 | Cost: 0.3747\n",
      "Epoch: 002/010 | Batch 400/468 | Cost: 0.3749\n",
      "Epoch: 003/010 | Batch 000/468 | Cost: 0.3082\n",
      "Epoch: 003/010 | Batch 200/468 | Cost: 0.2842\n",
      "Epoch: 003/010 | Batch 400/468 | Cost: 0.2252\n",
      "Epoch: 004/010 | Batch 000/468 | Cost: 0.1634\n",
      "Epoch: 004/010 | Batch 200/468 | Cost: 0.2194\n",
      "Epoch: 004/010 | Batch 400/468 | Cost: 0.2034\n",
      "Epoch: 005/010 | Batch 000/468 | Cost: 0.2358\n",
      "Epoch: 005/010 | Batch 200/468 | Cost: 0.2009\n",
      "Epoch: 005/010 | Batch 400/468 | Cost: 0.0824\n",
      "Epoch: 006/010 | Batch 000/468 | Cost: 0.1473\n",
      "Epoch: 006/010 | Batch 200/468 | Cost: 0.1436\n",
      "Epoch: 006/010 | Batch 400/468 | Cost: 0.2141\n",
      "Epoch: 007/010 | Batch 000/468 | Cost: 0.3440\n",
      "Epoch: 007/010 | Batch 200/468 | Cost: 0.1331\n",
      "Epoch: 007/010 | Batch 400/468 | Cost: 0.1123\n",
      "Epoch: 008/010 | Batch 000/468 | Cost: 0.1986\n",
      "Epoch: 008/010 | Batch 200/468 | Cost: 0.1621\n",
      "Epoch: 008/010 | Batch 400/468 | Cost: 0.1798\n",
      "Epoch: 009/010 | Batch 000/468 | Cost: 0.1393\n",
      "Epoch: 009/010 | Batch 200/468 | Cost: 0.2675\n",
      "Epoch: 009/010 | Batch 400/468 | Cost: 0.1482\n",
      "Epoch: 010/010 | Batch 000/468 | Cost: 0.1138\n",
      "Epoch: 010/010 | Batch 200/468 | Cost: 0.1673\n",
      "Epoch: 010/010 | Batch 400/468 | Cost: 0.1629\n"
     ]
    }
   ],
   "source": [
    "from condor_pytorch.dataset import levels_from_labelbatch\n",
    "from condor_pytorch.losses import condor_negloglikeloss\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    model = model.train()\n",
    "    for batch_idx, (features, class_labels) in enumerate(train_loader):\n",
    "\n",
    "        ##### Convert class labels for CONDOR\n",
    "        levels = levels_from_labelbatch(class_labels, \n",
    "                                        num_classes=NUM_CLASSES)\n",
    "        ###--------------------------------------------------------------------###\n",
    "        features = features.to(DEVICE)\n",
    "        levels = levels.to(DEVICE)\n",
    "        logits = model(features)\n",
    "        \n",
    "        #### CONDOR loss \n",
    "        cost = cost = condor_negloglikeloss(logits, levels)\n",
    "        ###--------------------------------------------------------------------###   \n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        ### LOGGING\n",
    "        if not batch_idx % 200:\n",
    "            print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n",
    "                   %(epoch+1, num_epochs, batch_idx, \n",
    "                     len(train_loader), cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 -- Evaluate model\n",
    "\n",
    "Finally, after model training, we can evaluate the performance of the model. For example, via the mean absolute error and mean squared error measures.\n",
    "\n",
    "For this, we are going to use the `logits_to_label` utility function from `condor_pytorch` to convert the probabilities back to the orginal label.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from condor_pytorch.dataset import logits_to_label\n",
    "from condor_pytorch.activations import ordinal_softmax\n",
    "from condor_pytorch.metrics import earth_movers_distance\n",
    "from condor_pytorch.metrics import ordinal_accuracy\n",
    "from condor_pytorch.metrics import mean_absolute_error\n",
    "\n",
    "def compute_mae_and_acc(model, data_loader, device):\n",
    "\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        emd, mae, acc, acc1, num_examples = 0., 0., 0., 0., 0\n",
    "\n",
    "        for i, (features, targets) in enumerate(data_loader):\n",
    "            ##### Convert class labels for CONDOR\n",
    "            levels = levels_from_labelbatch(targets, \n",
    "                                        num_classes=NUM_CLASSES)\n",
    "            features = features.to(device)\n",
    "            levels = levels.to(device)\n",
    "            targets = targets.float().to(device)\n",
    "            ids = targets.long()\n",
    "\n",
    "            logits = model(features)\n",
    "            predicted_labels = logits_to_label(logits).float()\n",
    "            predicted_probs = ordinal_softmax(logits).float()\n",
    "\n",
    "            num_examples += targets.size(0)\n",
    "            mae  += mean_absolute_error(logits,levels,reduction='sum')\n",
    "            acc  += ordinal_accuracy(logits,levels,tolerance=0,reduction='sum')\n",
    "            acc1 += ordinal_accuracy(logits,levels,tolerance=1,reduction='sum')\n",
    "            emd  += earth_movers_distance(logits,levels,reduction='sum')\n",
    "\n",
    "        mae  = mae / num_examples\n",
    "        acc  = acc / num_examples\n",
    "        acc1 = acc1 / num_examples\n",
    "        emd  = emd / num_examples\n",
    "        return mae, acc, acc1, emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mae, train_acc, train_acc1, train_emd = compute_mae_and_acc(model, train_loader, DEVICE)\n",
    "test_mae, test_acc, test_acc1, test_emd = compute_mae_and_acc(model, test_loader, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error (train/test): 0.15 | 0.15\n",
      "Accuracy tolerance 0 (train/test): 0.96 | 0.96\n",
      "Accuracy tolerance 1 (train/test): 0.97 | 0.97\n",
      "Earth movers distance (train/test): 0.251 | 0.247\n"
     ]
    }
   ],
   "source": [
    "print(f'Mean absolute error (train/test): {train_mae:.2f} | {test_mae:.2f}')\n",
    "print(f'Accuracy tolerance 0 (train/test): {train_acc:.2f} | {test_acc:.2f}')\n",
    "print(f'Accuracy tolerance 1 (train/test): {train_acc1:.2f} | {test_acc1:.2f}')\n",
    "print(f'Earth movers distance (train/test): {train_emd:.3f} | {test_emd:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
